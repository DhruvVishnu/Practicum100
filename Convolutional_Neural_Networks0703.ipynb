{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvVishnu/Practicum100/blob/main/Convolutional_Neural_Networks0703.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDWrFwZtq-bd"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qW68uf8N5p9"
      },
      "source": [
        "# CNN workshop\n",
        "\n",
        "In this workshop you will be asked to solve different tasks using CNNs.\n",
        "\n",
        "You will need to apply concepts and techniques seen in the previous notebooks. Feel free to consult them, copy and paste (and then edit) snippes of code, look for help on the keras documentation pages and on google (stackoverflow is a great source of informations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIO6vQoZ_ruV"
      },
      "source": [
        "\n",
        "\n",
        "## Exercise 1 - Image classification from scratch: ~1:30 hours\n",
        "\n",
        "- dataset: CIFAR10\n",
        "- techniques: Normalization, CNNs, Dropout, classification.\n",
        "\n",
        "\n",
        "create a CNN classifier.\n",
        "\n",
        "- Aim for **at least 45% accuracy on the test set**.\n",
        "\n",
        "- Experiment with the architecture (# layers, # filters, different pooling layers, dropout).\n",
        "\n",
        "- You can encode the classes or not (change loss accordingly).\n",
        "\n",
        "- Mind the input shape (these are color images).\n",
        "\n",
        "- try to avoid overfitting, you can use dropout layers and/or an early stopping callback.\n",
        "\n",
        "- note that the most used optimizers for cnns are 'sgd' and 'adam'. If you want, you can call their classes in order to change the default parameters.\n",
        "\n",
        "- you can experiment also with batch_size\n",
        "\n",
        "- this is not an easy task such as MNIST or fashion MNIST, you should at least train for a number of epochs > 20 but < 30. As a **baseline** my model reached accuracy **~ 30% at epoch 10**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyL5JJFzvVio"
      },
      "source": [
        "# load the data\n",
        "(x_train_raw, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTTLi5NPr612",
        "outputId": "74941c0c-9e2f-43ad-aadb-d6a9dc01dfdb"
      },
      "source": [
        "x_train_raw.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0t5rd0jsC86"
      },
      "source": [
        "# we reserve 10000 examples as the validation set\n",
        "x_train, x_valid = x_train_raw[:40000], x_train_raw[40000:]\n",
        "y_train, y_valid = y_train[:40000], y_train[40000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBlykw_GwcU6",
        "outputId": "097d0ce1-d9f8-4218-e5e4-7a76179d1386"
      },
      "source": [
        "x_train.shape, x_valid.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 32, 32, 3), (10000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ6OSdP-w0AB",
        "outputId": "0f08063c-0901-4921-e7cb-d97d0d547f07"
      },
      "source": [
        "# we have 10 classes\n",
        "np.unique(y_train, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              " array([3986, 3986, 4048, 3984, 4003, 3975, 4020, 4023, 3997, 3978]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73tsOuN_J20p"
      },
      "source": [
        "# start you work here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jE9Ya4dsTS4"
      },
      "source": [
        "- normalize the images (look at how we did in yesterday's notebook).\n",
        "\n",
        "- encode the classes (or not)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVBLnUz0sXq4"
      },
      "source": [
        "# normalize data\n",
        "\n",
        "# encode classes (or not)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehMp6dXmxFgw"
      },
      "source": [
        "Now you are ready to create the net:\n",
        "- create\n",
        "- compile\n",
        "- fit\n",
        "\n",
        "Check the validation metric, if you are not satisfied, clean the graph and create a new model. \n",
        "\n",
        "When you are satisfied you can evaluate on the test set.\n",
        "\n",
        "You can use this function to plot the training curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5lK85MExpKk"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "def plot_training_curve(history):\n",
        "    df = pd.DataFrame(history.history)\n",
        "    loss_cols = [x for x in df.columns if 'loss' in x]\n",
        "    df_loss = df[loss_cols].reset_index().rename(columns={'index': 'epoch'})\n",
        "    df_loss = pd.melt(df_loss, id_vars='epoch')\n",
        "    sns.lineplot(data=df_loss, x='epoch', y='value', hue='variable')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcz1RhgwsZN9"
      },
      "source": [
        "# start coding the model from here - use as many cells as you want."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJocI4fdAH6q"
      },
      "source": [
        "## Exercise 2 - Transfer Learning + Classification ~1:45 hours\n",
        "\n",
        "- dataset: 'horses_or_humans'\n",
        "- techniques: Normalization, CNNs, Dropout, Data augmentation, classification, transfer learning.\n",
        "\n",
        "This task is similar to the guided exercise we did on transfer learning on the 'tf_flowers' dataset. 'horses_or_humans' is another tfds dataset.\n",
        "\n",
        "- download the data, training set (60%-80% of the whole dataset), validation set (80%-90%), testing set (remaining 10%)\n",
        "\n",
        "- if you want you can augment your data as we did for the tf_flowers dataset\n",
        "\n",
        "- check how many classes are there\n",
        "\n",
        "- create the model by using Xception's base model and adding a pooling layer + a classification layer as we did.\n",
        "\n",
        "- rembember that you **have** to preprocess the data according to Xception preprocessing.\n",
        "\n",
        "- train the model keeping the weights of the base model frozen\n",
        "\n",
        "- to further improve the model, you can try to retrain the model after having unfrozen the base model weights\n",
        "\n",
        "- training will be slow, train for ~3 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYeZ-wSZNDJ_"
      },
      "source": [
        "# clear the keras graphs\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqRDwCniNDf4"
      },
      "source": [
        "# start coding the model from here - use as many cells as you want."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuMyOFQ3LxJY"
      },
      "source": [
        "## Exercise 3 (bonus) \n",
        "\n",
        "Find a dataset ( [keras dataset](https://keras.io/api/datasets/) or [tensorflow dataset](https://www.tensorflow.org/datasets/catalog/overview)) and create a CNN based computer vision model entirely by yourself, either from scratch or using transfer learning (overview of available pre trained [models](https://keras.io/api/applications/) in keras)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T32xDf4TL4Bn"
      },
      "source": [
        "# start coding the from here - use as many cells as you want."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9dhdpClNIOi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}